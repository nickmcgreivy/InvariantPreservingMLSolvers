{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37e5428",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we will train a machine learned FV solver to solve the 1D Burgers' equation at reduced resolution. Our objective is to study whether is it better to use the a linear flux correction or non-linear stencil for for the ML flux.\n",
    "\n",
    "The linear stencil is given by\n",
    "\n",
    "$$f_{j+1/2} = \\sum_{k} s_{j+1/2,k} f_{j+k}$$\n",
    "\n",
    "where $f_{j+k} = u_{j+k}^2/2$. The non-linear stencil is given by\n",
    "\n",
    "$$f_{j+1/2} = u_{j+1/2}^2/2, \\hspace{0.5cm} u_{j+1/2} = \\sum_{k} s_{j+1/2, k} u_{j+k}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ad011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths\n",
    "import sys\n",
    "basedir = '/Users/nickm/thesis/icml2023paper/1d_burgers'\n",
    "readwritedir = '/Users/nickm/thesis/icml2023paper/1d_burgers'\n",
    "\n",
    "sys.path.append('{}/core'.format(basedir))\n",
    "sys.path.append('{}/simulate'.format(basedir))\n",
    "sys.path.append('{}/ml'.format(basedir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "from jax import config, vmap\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "import xarray\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae413a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal packages\n",
    "from flux import Flux\n",
    "from initialconditions import get_a0, get_initial_condition_fn, get_a, forcing_func_sum_of_modes\n",
    "from simparams import CoreParams, SimulationParams\n",
    "from legendre import generate_legendre\n",
    "from simulations import BurgersFVSim\n",
    "from trajectory import get_trajectory_fn, get_inner_fn\n",
    "from trainingutils import save_training_data\n",
    "from mlparams import TrainingParams, StencilParams\n",
    "from model import LearnedStencil\n",
    "from trainingutils import (get_loss_fn, get_batch_fn, get_idx_gen, train_model, \n",
    "                           compute_losses_no_model, init_params, save_training_params, load_training_params)\n",
    "from helper import convert_FV_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def plot_fv(a, core_params, color=\"blue\"):\n",
    "    plot_dg(a[...,None], core_params, color=color)\n",
    "    \n",
    "def plot_fv_trajectory(trajectory, core_params, t_inner, color='blue'):\n",
    "    plot_dg_trajectory(trajectory[...,None], core_params, t_inner, color=color)\n",
    "    \n",
    "def plot_dg(a, core_params, color='blue'):\n",
    "    p = 1\n",
    "    def evalf(x, a, j, dx, leg_poly):\n",
    "        x_j = dx * (0.5 + j)\n",
    "        xi = (x - x_j) / (0.5 * dx)\n",
    "        vmap_polyval = vmap(jnp.polyval, (0, None), -1)\n",
    "        poly_eval = vmap_polyval(leg_poly, xi)  # nx, p array\n",
    "        return jnp.sum(poly_eval * a, axis=-1)\n",
    "\n",
    "    NPLOT = [2,2,5,7][p-1]\n",
    "    nx = a.shape[0]\n",
    "    dx = core_params.Lx / nx\n",
    "    xjs = jnp.arange(nx) * core_params.Lx / nx\n",
    "    xs = xjs[None, :] + jnp.linspace(0.0, dx, NPLOT)[:, None]\n",
    "    vmap_eval = vmap(evalf, (1, 0, 0, None, None), 1)\n",
    "\n",
    "    a_plot = vmap_eval(xs, a, jnp.arange(nx), dx, generate_legendre(p))\n",
    "    a_plot = a_plot.T.reshape(-1)\n",
    "    xs = xs.T.reshape(-1)\n",
    "    coords = {('x'): xs}\n",
    "    data = xarray.DataArray(a_plot, coords=coords)\n",
    "    data.plot(color=color)\n",
    "\n",
    "def plot_dg_trajectory(trajectory, core_params, t_inner, color='blue'):\n",
    "    p = 1\n",
    "    NPLOT = [2,2,5,7][p-1]\n",
    "    nx = trajectory.shape[1]\n",
    "    dx = core_params.Lx / nx\n",
    "    xjs = jnp.arange(nx) * core_params.Lx / nx\n",
    "    xs = xjs[None, :] + jnp.linspace(0.0, dx, NPLOT)[:, None]\n",
    "    \n",
    "    def get_plot_repr(a):\n",
    "        def evalf(x, a, j, dx, leg_poly):\n",
    "            x_j = dx * (0.5 + j)\n",
    "            xi = (x - x_j) / (0.5 * dx)\n",
    "            vmap_polyval = vmap(jnp.polyval, (0, None), -1)\n",
    "            poly_eval = vmap_polyval(leg_poly, xi)  # nx, p array\n",
    "            return jnp.sum(poly_eval * a, axis=-1)\n",
    "\n",
    "        vmap_eval = vmap(evalf, (1, 0, 0, None, None), 1)\n",
    "        return vmap_eval(xs, a, jnp.arange(nx), dx, generate_legendre(p)).T\n",
    "\n",
    "    get_trajectory_plot_repr = vmap(get_plot_repr)\n",
    "    trajectory_plot = get_trajectory_plot_repr(trajectory)\n",
    "\n",
    "    outer_steps = trajectory.shape[0]\n",
    "    \n",
    "    trajectory_plot = trajectory_plot.reshape(outer_steps, -1)\n",
    "    xs = xs.T.reshape(-1)\n",
    "    coords = {\n",
    "        'x': xs,\n",
    "        'time': t_inner * jnp.arange(outer_steps)\n",
    "    }\n",
    "    xarray.DataArray(trajectory_plot, dims=[\"time\", \"x\"], coords=coords).plot(\n",
    "        col='time', col_wrap=5, color=color)\n",
    "    \n",
    "def plot_multiple_fv_trajectories(trajectories, core_params, t_inner):\n",
    "    plot_multiple_dg_trajectories([trajectory[..., None] for trajectory in trajectories], core_params, t_inner)\n",
    "\n",
    "def plot_multiple_dg_trajectories(trajectories, core_params, t_inner):\n",
    "    outer_steps = trajectories[0].shape[0]\n",
    "    nx = trajectories[0].shape[1]\n",
    "    p = 1\n",
    "    NPLOT = [2,2,5,7][p-1]\n",
    "    dx = core_params.Lx / nx\n",
    "    xjs = jnp.arange(nx) * core_params.Lx / nx\n",
    "    xs = xjs[None, :] + jnp.linspace(0.0, dx, NPLOT)[:, None]\n",
    "    \n",
    "    def get_plot_repr(a):\n",
    "        def evalf(x, a, j, dx, leg_poly):\n",
    "            x_j = dx * (0.5 + j)\n",
    "            xi = (x - x_j) / (0.5 * dx)\n",
    "            vmap_polyval = vmap(jnp.polyval, (0, None), -1)\n",
    "            poly_eval = vmap_polyval(leg_poly, xi)  # nx, p array\n",
    "            return jnp.sum(poly_eval * a, axis=-1)\n",
    "\n",
    "        vmap_eval = vmap(evalf, (1, 0, 0, None, None), 1)\n",
    "        return vmap_eval(xs, a, jnp.arange(nx), dx, generate_legendre(p)).T\n",
    "\n",
    "    get_trajectory_plot_repr = vmap(get_plot_repr)\n",
    "    trajectory_plots = []\n",
    "    for trajectory in trajectories:  \n",
    "        trajectory_plots.append(get_trajectory_plot_repr(trajectory).reshape(outer_steps, -1))\n",
    "        \n",
    "    xs = xs.T.reshape(-1)\n",
    "    coords = {\n",
    "        'x': xs,\n",
    "        'time': t_inner * jnp.arange(outer_steps)\n",
    "    }\n",
    "    xarray.DataArray(trajectory_plots, dims=[\"stack\", \"time\", \"x\"], coords=coords).plot.line(\n",
    "        col='time', hue=\"stack\", col_wrap=5)\n",
    "    \n",
    "def get_core_params(Lx = 1.0, flux='godunov', nu = 0.0):\n",
    "    return CoreParams(Lx, flux, nu)\n",
    "\n",
    "def get_sim_params(name = \"test\", cfl_safety=0.3, rk='ssp_rk3'):\n",
    "    return SimulationParams(name, basedir, readwritedir, cfl_safety, rk)\n",
    "\n",
    "def get_training_params(n_data, train_id=\"test\", batch_size=4, learning_rate=1e-3, num_epochs = 10, optimizer='sgd'):\n",
    "    return TrainingParams(n_data, num_epochs, train_id, batch_size, learning_rate, optimizer)\n",
    "\n",
    "def get_stencil_params(kernel_size = 3, kernel_out = 4, stencil_width=4, depth = 3, width = 16):\n",
    "    return StencilParams(kernel_size, kernel_out, stencil_width, depth, width)\n",
    "\n",
    "\n",
    "def l2_norm_trajectory(trajectory):\n",
    "    return (jnp.mean(trajectory**2, axis=1))\n",
    "    \n",
    "def get_model(core_params, stencil_params, delta=True):\n",
    "    features = [stencil_params.width for _ in range(stencil_params.depth - 1)]\n",
    "    return LearnedStencil(features, stencil_params.kernel_size, stencil_params.kernel_out, stencil_params.stencil_width, delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a764bc88",
   "metadata": {},
   "source": [
    "### Finite Volume\n",
    "\n",
    "##### Training Loop\n",
    "\n",
    "First, we will generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd99d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "init_description = 'zeros'\n",
    "fv_flux_baseline = 'weno' # learning a correction to the weno scheme\n",
    "omega_max = 0.4\n",
    "kwargs_init = {'min_num_modes': 2, 'max_num_modes': 6, 'min_k': 0, 'max_k': 3, 'amplitude_max': 1.0}\n",
    "kwargs_core = {'Lx': 2 * jnp.pi, 'flux': 'weno', 'nu': 0.01}\n",
    "kwargs_core_god = {'Lx': 2 * jnp.pi, 'flux': 'godunov', 'nu': 0.01}\n",
    "kwargs_core_bad = {'Lx': 2 * jnp.pi, 'flux': 'godunovbad', 'nu': 0.01}\n",
    "kwargs_core_bad2 = {'Lx': 2 * jnp.pi, 'flux': 'wenobad', 'nu': 0.01}\n",
    "kwargs_forcing = {'min_num_modes': 20, 'max_num_modes': 20, 'min_k': 3, 'max_k': 6, 'amplitude_max': 0.5, 'omega_max': omega_max}\n",
    "kwargs_sim = {'name' : \"burgers_hoyer\", 'cfl_safety' : 0.3, 'rk' : 'ssp_rk3'}\n",
    "kwargs_train_FV = {'train_id': \"burgers_hoyer\", 'batch_size' : 128, 'optimizer': 'adam', 'num_epochs' : 100}\n",
    "kwargs_stencil = {'kernel_size' : 5, 'kernel_out' : 4, 'stencil_width' : 6, 'depth' : 3, 'width' : 32}\n",
    "n_runs = 800\n",
    "t_inner_train = 0.1\n",
    "Tf = 1.0\n",
    "outer_steps_train = int(Tf/t_inner_train)\n",
    "nx_exact = 512\n",
    "nxs = [16, 32, 64, 128, 256] # [8, 16, 32, 64]\n",
    "learning_rate_list = [3e-3,3e-3, 3e-3, 3e-3, 3e-3] #[1e-2, 1e-2, 1e-4, 1e-5]\n",
    "assert len(nxs) == len(learning_rate_list)\n",
    "key = jax.random.PRNGKey(12)\n",
    "\n",
    "delta = True\n",
    "\n",
    "# setup\n",
    "core_params = get_core_params(**kwargs_core)\n",
    "core_params_god = get_core_params(**kwargs_core_god)\n",
    "core_params_bad = get_core_params(**kwargs_core_bad)\n",
    "core_params_bad2 = get_core_params(**kwargs_core_bad2)\n",
    "sim_params = get_sim_params(**kwargs_sim)\n",
    "n_data = n_runs * outer_steps_train\n",
    "training_params_list = [get_training_params(n_data, **kwargs_train_FV, learning_rate = lr) for lr in learning_rate_list]\n",
    "stencil_params = get_stencil_params(**kwargs_stencil)\n",
    "sim = BurgersFVSim(core_params, sim_params, delta=delta, omega_max = omega_max)\n",
    "sim_god = BurgersFVSim(core_params_god, sim_params, delta=delta, omega_max = omega_max)\n",
    "sim_bad = BurgersFVSim(core_params_bad, sim_params, delta=delta, omega_max = omega_max)\n",
    "sim_bad2 = BurgersFVSim(core_params_bad2, sim_params, delta=delta, omega_max = omega_max)\n",
    "init_fn = lambda key: get_initial_condition_fn(core_params, init_description, key=key, **kwargs_init)\n",
    "forcing_fn = forcing_func_sum_of_modes(core_params.Lx, **kwargs_forcing)\n",
    "model = get_model(core_params, stencil_params, delta=delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a824db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_training_data(key, init_fn, forcing_fn, core_params, sim_params, sim, t_inner_train, outer_steps_train, n_runs, nx_exact, nxs, delta=delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(43)\n",
    "#i_params = init_params(key, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i, nx in enumerate(nxs):\n",
    "    print(nx)\n",
    "    training_params = training_params_list[i]\n",
    "    idx_fn = lambda key: get_idx_gen(key, training_params)\n",
    "    batch_fn = get_batch_fn(core_params, sim_params, training_params, nx, delta=delta)\n",
    "    loss_fn = get_loss_fn(model, core_params, delta=delta)\n",
    "    losses, params = train_model(model, i_params, training_params, key, idx_fn, batch_fn, loss_fn)\n",
    "    save_training_params(nx, sim_params, training_params, params, losses)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff423c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Equation is 1D Burgers\")\n",
    "for i, nx in enumerate(nxs):\n",
    "    losses, _ = load_training_params(nx, sim_params, training_params_list[i], model)\n",
    "    plt.plot(losses, label=nx)\n",
    "    print(\"nx is {}, average loss is {}\".format(nx, jnp.mean(losses)))\n",
    "plt.ylim([0,4.0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0bc27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# pick a key that gives something nice\n",
    "key = jax.random.PRNGKey(29)\n",
    "\n",
    "key1, key2 = jax.random.split(key)\n",
    "\n",
    "\n",
    "for i, nx in enumerate(nxs):\n",
    "    print(\"nx is {}\".format(nx))\n",
    "    f_init = get_initial_condition_fn(core_params, init_description, key=key1, **kwargs_init)\n",
    "    f_forcing = forcing_fn(key2)\n",
    "    t0 = 0.0\n",
    "    a0 = get_a0(f_init, core_params, nx)\n",
    "    a0_exact = get_a0(f_init, core_params, nx_exact)\n",
    "    x0 = (a0, t0)\n",
    "    x0_exact = (a0_exact, t0)\n",
    "    \n",
    "    t_inner = 2.0\n",
    "    outer_steps = 20\n",
    "    \n",
    "    # without params\n",
    "    step_fn = lambda a, t, dt: sim.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "    inner_fn = get_inner_fn(step_fn, sim.dt_fn, t_inner)\n",
    "    trajectory_fn = get_trajectory_fn(inner_fn, outer_steps)\n",
    "    \n",
    "    # godunovbad\n",
    "    step_fn_bad = lambda a, t, dt: sim_bad.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "    inner_fn_bad = get_inner_fn(step_fn_bad, sim_bad.dt_fn, t_inner)\n",
    "    trajectory_fn_bad = get_trajectory_fn(inner_fn_bad, outer_steps)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    _, params = load_training_params(nx, sim_params, training_params_list[i], model)\n",
    "    # with params\n",
    "    sim_model = BurgersFVSim(core_params, sim_params, model=model, params=params, delta=delta, omega_max = omega_max)\n",
    "    step_fn_model = lambda a, t, dt: sim_model.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "    inner_fn_model = get_inner_fn(step_fn_model, sim_model.dt_fn, t_inner)\n",
    "    trajectory_fn_model = get_trajectory_fn(inner_fn_model, outer_steps)\n",
    "    trajectory_model, _ = trajectory_fn_model(x0)    \n",
    "\n",
    "    # with gs\n",
    "    sim_model_gs = BurgersFVSim(core_params, sim_params, model=model, params=params, global_stabilization = True, delta=delta, omega_max = omega_max)\n",
    "    step_fn_model_gs = lambda a, t, dt: sim_model_gs.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "    inner_fn_model_gs = get_inner_fn(step_fn_model_gs, sim_model_gs.dt_fn, t_inner)\n",
    "    trajectory_fn_model_gs = get_trajectory_fn(inner_fn_model_gs, outer_steps)\n",
    "    trajectory_model_gs, _ = trajectory_fn_model_gs(x0)    \n",
    "    \"\"\"\n",
    "    \n",
    "    # exact trajectory\n",
    "    trajectory, _ = trajectory_fn(x0)\n",
    "    trajectory_bad, _ = trajectory_fn_bad(x0)\n",
    "    trajectory_exact, _ = trajectory_fn(x0_exact)\n",
    "\n",
    "    trajectory_exact_ds = vmap(convert_FV_representation, (0, None, None), 0)(trajectory_exact, nx, core_params.Lx)\n",
    "\n",
    "    \n",
    "    \n",
    "    plot_multiple_fv_trajectories([trajectory, trajectory_bad, trajectory_exact_ds], core_params, t_inner)\n",
    "    plt.ylim([-1.5, 1.5])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(l2_norm_trajectory(trajectory))\n",
    "    plt.plot(l2_norm_trajectory(trajectory_bad))\n",
    "    plt.plot(l2_norm_trajectory(trajectory_exact_ds))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ddc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 10\n",
    "\n",
    "#mae_weno = []\n",
    "mae_god = []\n",
    "#mae_bad = []\n",
    "#mae_bad2 = []\n",
    "#mae_zeros = []\n",
    "\n",
    "def mae_loss(v, v_ex):\n",
    "    diff = v - v_ex\n",
    "    return jnp.mean(jnp.absolute(diff))\n",
    "\n",
    "for i, nx in enumerate(nxs):\n",
    "    \n",
    "    key = jax.random.PRNGKey(11)\n",
    "    \n",
    "    #_, params = load_training_params(nx, sim_params, training_params_list[i], model)\n",
    "    t_inner = 0.1\n",
    "    outer_steps = 150\n",
    "    outer_steps_warmup = 100\n",
    "    \n",
    "    mae_weno_nx = 0.0\n",
    "    mae_god_nx = 0.0\n",
    "    mae_bad_nx = 0.0\n",
    "    mae_bad2_nx = 0.0\n",
    "    mae_zeros_nx = 0.0\n",
    "    \n",
    "    vmap_convert = vmap(convert_FV_representation, (0, None, None), 0)\n",
    "    \n",
    "    for n in range(N):\n",
    "        print(n)\n",
    "        \n",
    "        key, init_key, forcing_key = jax.random.split(key, 3)\n",
    "        f_forcing = forcing_fn(forcing_key)\n",
    "        f_init = get_initial_condition_fn(core_params, init_description, key=init_key, **kwargs_init)\n",
    "        \n",
    "        # warmup\n",
    "        step_fn = lambda a, t, dt: sim.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "        inner_fn_weno = get_inner_fn(step_fn, sim.dt_fn, t_inner)\n",
    "        trajectory_fn_warmup = get_trajectory_fn(inner_fn_weno, outer_steps_warmup, start_with_input=False)\n",
    "        trajectory_fn_weno = get_trajectory_fn(inner_fn_weno, outer_steps)\n",
    "\n",
    "        step_fn_god = lambda a, t, dt: sim_god.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "        inner_fn_god = get_inner_fn(step_fn_god, sim_god.dt_fn, t_inner)\n",
    "        trajectory_fn_god = get_trajectory_fn(inner_fn_god, outer_steps)\n",
    "        \n",
    "        step_fn_bad = lambda a, t, dt: sim_bad.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "        inner_fn_bad = get_inner_fn(step_fn_bad, sim_bad.dt_fn, t_inner)\n",
    "        trajectory_fn_bad = get_trajectory_fn(inner_fn_bad, outer_steps)\n",
    "        \n",
    "        step_fn_bad2 = lambda a, t, dt: sim_bad2.step_fn(a, t, dt, forcing_func = f_forcing)\n",
    "        inner_fn_bad2 = get_inner_fn(step_fn_bad2, sim_bad2.dt_fn, t_inner)\n",
    "        trajectory_fn_bad2 = get_trajectory_fn(inner_fn_bad2, outer_steps)\n",
    "\n",
    "        \n",
    "        # warmup\n",
    "        t0 = 0.0\n",
    "        a0_exact = get_a0(f_init, core_params, nx_exact)\n",
    "        x0_exact = (a0_exact, t0)\n",
    "        trajectory_exact, trajectory_t = trajectory_fn_warmup(x0_exact)\n",
    "        a0_exact = trajectory_exact[-1]\n",
    "        t0 = trajectory_t[-1]\n",
    "        a0 = convert_FV_representation(a0_exact, nx, core_params.Lx)\n",
    "        x0 = (a0, t0)\n",
    "        x0_exact = (a0_exact, t0)\n",
    "        \n",
    "        \n",
    "        #trajectory_weno, _ = trajectory_fn_weno(x0)\n",
    "        trajectory_god, _ = trajectory_fn_god(x0)\n",
    "        #trajectory_bad, _ = trajectory_fn_bad(x0)\n",
    "        #trajectory_bad2, _ = trajectory_fn_bad2(x0)\n",
    "        \n",
    "        # Exact trajectory\n",
    "        trajectory_exact, _ = trajectory_fn_weno(x0_exact)\n",
    "        trajectory_exact_ds = vmap_convert(trajectory_exact, nx, core_params.Lx)\n",
    "        \n",
    "        #mae_weno_nx += mae_loss(trajectory_weno, trajectory_exact_ds) / N\n",
    "        mae_god_nx += mae_loss(trajectory_god, trajectory_exact_ds) / N\n",
    "        #mae_bad_nx += mae_loss(trajectory_bad, trajectory_exact_ds) / N\n",
    "        #mae_bad2_nx += mae_loss(trajectory_bad2, trajectory_exact_ds) / N\n",
    "        #mae_zeros_nx += mae_loss(jnp.zeros(trajectory_exact_ds.shape), trajectory_exact_ds) / N\n",
    "        \n",
    "    #mae_weno.append(mae_weno_nx)\n",
    "    mae_god.append(mae_god_nx)\n",
    "    #mae_bad.append(mae_bad_nx)\n",
    "    #mae_bad2.append(mae_bad2_nx)\n",
    "    #mae_zeros.append(mae_zeros_nx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "print(mae_weno)\n",
    "print(mae_god)\n",
    "print(mae_bad)\n",
    "print(mae_bad2)\n",
    "print(mae_zeros)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(7, 3.25))\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "linewidth = 3\n",
    "\n",
    "maes = [mae_weno, mae_god, mae_bad, mae_bad2, mae_zeros]\n",
    "labels = [\"WENO\", \"GODUNOV\", \"GODUNOV Bad\", \"WENO Bad\", \"zeros loss\"]\n",
    "colors = [\"blue\", \"red\", \"purple\", \"green\", \"pink\"]\n",
    "linestyles = [\"solid\", \"solid\", \"solid\", \"solid\", \"solid\"]\n",
    "\n",
    "for k, mae in enumerate(maes):\n",
    "    plt.loglog(nxs, mae, label = labels[k], color=colors[k], linewidth=linewidth, linestyle=linestyles[k])\n",
    "plt.loglog(nxs, [1e-1] * len(nxs), color='black', linewidth=0.5)\n",
    "plt.loglog(nxs, [1e-2] * len(nxs), color='black', linewidth=0.5)\n",
    "plt.loglog(nxs, [1e-3] * len(nxs), color='black', linewidth=0.5)\n",
    "axs.set_xticks([64, 32, 16, 8])\n",
    "axs.set_xticklabels([\"N=64\", \"N=32\", \"N=16\", \"N=8\"], fontsize=18)\n",
    "axs.set_yticks([1e-3, 1e-2, 1e-1, 1e0])\n",
    "axs.set_yticklabels([\"$10^{-3}$\", \"$10^{-2}$\", \"$10^{-1}$\", \"$10^0$\"], fontsize=18)\n",
    "axs.minorticks_off()\n",
    "axs.set_ylabel(\"MAE\", fontsize=18)\n",
    "axs.text(0.3, 0.95, '$t=1$', transform=axs.transAxes, fontsize=18, verticalalignment='top')\n",
    "\n",
    "\n",
    "handles = []\n",
    "for k, mae in enumerate(maes):\n",
    "    handles.append(\n",
    "        mlines.Line2D(\n",
    "            [],\n",
    "            [],\n",
    "            color=colors[k],\n",
    "            linewidth=linewidth,\n",
    "            label=labels[k],\n",
    "            linestyle=linestyles[k]\n",
    "        )\n",
    "    )\n",
    "axs.legend(handles=handles,loc=(0.655,0.45) , prop={'size': 15}, frameon=False)\n",
    "plt.ylim([2.5e-5, 1e0+1e-1])\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "#plt.savefig('mse_vs_nx.png')\n",
    "#plt.savefig('mse_vs_nx.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9686c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
